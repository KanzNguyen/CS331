{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10074080,"sourceType":"datasetVersion","datasetId":6209621}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install streamlit\n!pip install streamlit localtunnel\n!pip install imutils\n!npm install -g localtunnel","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:12:19.306177Z","iopub.execute_input":"2024-12-10T16:12:19.308063Z","iopub.status.idle":"2024-12-10T16:12:46.025326Z","shell.execute_reply.started":"2024-12-10T16:12:19.308005Z","shell.execute_reply":"2024-12-10T16:12:46.024311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile app_temp.py\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport imutils\nimport streamlit as st\nfrom PIL import Image\nimport torch\nfrom torchvision import models, transforms\nfrom torch import nn\nimport joblib\nfrom skimage import data, color\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\nfrom scipy import ndimage\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n# Hàm xử lý hình ảnh\ndef process_image(image_path):\n    img = cv2.imread(image_path)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n    thresh = cv2.threshold(gray, 23, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n\n    img_cnt = img_rgb.copy()\n    img_cnt = cv2.drawContours(img_cnt, cnts, -1, (0, 255, 255), 4)\n\n    l, r, t, b = [], [], [], []\n    for contour in cnts:\n        leftmost = tuple(contour[contour[:, :, 0].argmin()][0])\n        rightmost = tuple(contour[contour[:, :, 0].argmax()][0])\n        topmost = tuple(contour[contour[:, :, 1].argmin()][0])\n        bottommost = tuple(contour[contour[:, :, 1].argmax()][0])\n        l.append(leftmost)\n        r.append(rightmost)\n        t.append(topmost)\n        b.append(bottommost)\n\n    leftmost = min(l, key=lambda x: x[0])\n    rightmost = max(r, key=lambda x: x[0])\n    topmost = min(t, key=lambda x: x[1])\n    bottommost = max(b, key=lambda x: x[1])\n\n    img_pnt = img_cnt.copy()\n    img_pnt = cv2.circle(img_pnt, leftmost, 5, (0, 0, 255), -1)\n    img_pnt = cv2.circle(img_pnt, rightmost, 5, (0, 255, 0), -1)\n    img_pnt = cv2.circle(img_pnt, topmost, 5, (255, 0, 0), -1)\n    img_pnt = cv2.circle(img_pnt, bottommost, 5, (255, 255, 0), -1)\n\n    ADD_PIXELS = 0\n    new_img = img_rgb[topmost[1]-ADD_PIXELS:bottommost[1]+ADD_PIXELS,\n                      leftmost[0]-ADD_PIXELS:rightmost[0]+ADD_PIXELS].copy()\n    resize_img = cv2.resize(new_img, (224, 224))\n\n    return img_rgb, gray, thresh, img_cnt, img_pnt, new_img, resize_img\n\n# Hàm tiền xử lý ảnh cho MobileNet và PCA\ndef preprocess_image(image, device):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    img = Image.fromarray(image)\n    img = transform(img).unsqueeze(0).to(device)\n    return img\n\ndef preprocess_image_pca(image):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ])\n    img = Image.fromarray(image)\n    img = transform(img).numpy().flatten()\n    return img\n\n# Load pre-trained MobileNet model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmobilenet_v3_large_model = models.mobilenet_v3_large(pretrained=True)\nmobilenet_v3_large_model = nn.Sequential(*list(mobilenet_v3_large_model.children())[:-1])\nmobilenet_v3_large_model = mobilenet_v3_large_model.to(device)\nmobilenet_v3_large_model.eval()\n\nresnet18_model = models.resnet18(pretrained=True)\nresnet18_model = nn.Sequential(*list(resnet18_model.children())[:-1])\nresnet18_model = resnet18_model.to(device)\nresnet18_model.eval()\n\n# Load other models and PCA\n\n# resnet with pca\nmodel1_resnet_pca = joblib.load('/kaggle/input/full-model/resnet 18/model1.pkl')\nmodel2_resnet_pca = joblib.load('/kaggle/input/full-model/resnet 18/model2.pkl')\nmodel3_resnet_pca = joblib.load('/kaggle/input/full-model/resnet 18/model3.pkl')\nensemble_model_svm_resnet_pca = joblib.load('/kaggle/input/full-model/resnet 18/ensemble_model_svm.pkl')\npca_model_resnet_pca = joblib.load('/kaggle/input/full-model/resnet 18/pca_model.pkl')\nsvm_model_resnet_pca = joblib.load('/kaggle/input/full-model/resnet 18/svm.pkl')\nscaler_model_resnet_pca = joblib.load('/kaggle/input/full-model/resnet 18/scaler.pkl')\n# resnet no pca\nmodel1_resnet = joblib.load('/kaggle/input/full-model/resnet 18 no pca/model1.pkl')\nmodel2_resnet = joblib.load('/kaggle/input/full-model/resnet 18 no pca/model2.pkl')\nmodel3_resnet = joblib.load('/kaggle/input/full-model/resnet 18 no pca/model3.pkl')\nensemble_model_svm_resnet = joblib.load('/kaggle/input/full-model/resnet 18 no pca/ensemble_model_svm.pkl')\npca_model_resnet = joblib.load('/kaggle/input/full-model/resnet 18 no pca/pca_model.pkl')\nsvm_model_resnet = joblib.load('/kaggle/input/full-model/resnet 18 no pca/svm.pkl')\nscaler_model_resnet = joblib.load('/kaggle/input/full-model/resnet 18 no pca/scaler.pkl')\n#mobilenet with pca\nmodel1_mobilenet_pca = joblib.load('/kaggle/input/full-model/mobilenet V3/model1.pkl')\nmodel2_mobilenet_pca = joblib.load('/kaggle/input/full-model/mobilenet V3/model2.pkl')\nmodel3_mobilenet_pca = joblib.load('/kaggle/input/full-model/mobilenet V3/model3.pkl')\nensemble_model_svm_mobilenet_pca = joblib.load('/kaggle/input/full-model/mobilenet V3/ensemble_model_svm.pkl')\npca_model_mobilenet_pca = joblib.load('/kaggle/input/full-model/mobilenet V3/pca_model.pkl')\nsvm_model_mobilenet_pca = joblib.load('/kaggle/input/full-model/mobilenet V3/svm.pkl')\nscaler_model_mobilenet_pca = joblib.load('/kaggle/input/full-model/mobilenet V3/scaler.pkl')\n#mobilenet no pca\nmodel1_mobilenet = joblib.load('/kaggle/input/full-model/mobilenet V3 no pca/model1.pkl')\nmodel2_mobilenet = joblib.load('/kaggle/input/full-model/mobilenet V3 no pca/model2.pkl')\nmodel3_mobilenet = joblib.load('/kaggle/input/full-model/mobilenet V3 no pca/model3.pkl')\nensemble_model_svm_mobilenet = joblib.load('/kaggle/input/full-model/mobilenet V3 no pca/ensemble_model_svm.pkl')\npca_model_mobilenet = joblib.load('/kaggle/input/full-model/mobilenet V3 no pca/pca_model.pkl')\nsvm_model_mobilenet = joblib.load('/kaggle/input/full-model/mobilenet V3 no pca/svm.pkl')\nscaler_model_mobilenet = joblib.load('/kaggle/input/full-model/mobilenet V3 no pca/scaler.pkl')\n\ndef read_and_convert_to_gray(image_path):\n    # Đọc ảnh bằng OpenCV\n    image = cv2.imread(image_path)\n    # Chuyển đổi ảnh sang thang độ xám\n    gray_image = color.rgb2gray(image)\n    return gray_image\ndef extract_features(image, model):\n    with torch.no_grad():\n        feature = model(image).squeeze().cpu().numpy()  # Đảm bảo chuyển tensor về CPU\n    return feature\n# Giao diện ứng dụng Streamlit\nst.title(\"MRI Image Classification\")\nuploaded_file = st.file_uploader(\"Upload MRI image\", type=[\"png\", \"jpg\", \"jpeg\"])\n\nif uploaded_file is not None:\n    with open(\"temp.png\", \"wb\") as f:\n        f.write(uploaded_file.getbuffer())\n    st.image(uploaded_file, caption=\"1. Original image\", width=300)\n\n    # Xử lý hình ảnh\n    original, gray, thresh, contours, extreme_points, cropped, resized = process_image(\"temp.png\")\n\n    # Hiển thị các bước xử lý\n    st.subheader(\"Preprocessing image\")\n    col1, col2, col3 = st.columns(3)\n\n    with col1:\n        st.image(gray, caption=\"2. Grayscale image\", use_container_width=True)\n        st.image(extreme_points, caption=\"5. Extreme points\", use_container_width=True)\n    with col2:\n        st.image(thresh, caption=\"3. Thresholding\", use_container_width=True)\n        st.image(cropped, caption=\"6. Cropped image\", use_container_width=True)\n\n    with col3:\n        st.image(contours, caption=\"4. Contours\", use_container_width=True)\n        st.image(resized, caption=\"7. Resized image (224x224)\", use_container_width=True)\n\n    model_choice = st.radio(\"Select classification method:\", (   \"Resnet18 + SVM\", \"Resnet18 + PCA + Ensemble Models\", \"Resnet18 + PCA + SVM\", \"Resnet18 + Ensemble Models\"\n                                                                ,\"MobilenetV3 + SVM\", \"MobilenetV3 + PCA + Ensemble Models\", \"MobilenetV3 + PCA + SVM\", \"MobilenetV3 + Ensemble Models\"))\n\n    if model_choice == \"MobilenetV3 + SVM\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, mobilenet_v3_large_model)\n        image_features_resnet = scaler_model_mobilenet.transform(image_features_resnet.reshape(1, -1))\n        y_pred = svm_model_mobilenet.predict(image_features_resnet)\n        predicted_label = y_pred[0]\n        img = load_img(\"temp.png\")\n        img_array = img_to_array(img)\n        st.subheader(f\"Prediction label: {y_pred[0]}\")\n        st.image(img_array.astype('uint8'), caption=f\"Predicted Label: {y_pred[0]}\", use_container_width=True)\n    elif model_choice == \"Resnet18 + SVM\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, resnet18_model)\n        image_features_resnet = scaler_model_resnet.transform(image_features_resnet.reshape(1, -1))\n        y_pred = svm_model_resnet.predict(image_features_resnet)\n        predicted_label = y_pred[0]\n        img = load_img(\"temp.png\")\n        img_array = img_to_array(img)\n        st.subheader(f\"Prediction label: {y_pred[0]}\")\n        st.image(img_array.astype('uint8'), caption=f\"Predicted Label: {y_pred[0]}\", use_container_width=True)\n    elif model_choice == \"MobilenetV3 + Ensemble Models\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, mobilenet_v3_large_model)\n        features_combined = image_features_resnet.reshape(1, -1)\n        y_pred1_prob = model1_mobilenet.predict(features_combined).flatten()\n        y_pred2_prob = model2_mobilenet.predict(features_combined).flatten()\n        y_pred3_prob = model3_mobilenet.predict(features_combined).flatten()\n        y_pred_probs = np.column_stack((y_pred1_prob, y_pred2_prob, y_pred3_prob))\n        y_pred_ensemble_svm = ensemble_model_svm_mobilenet.predict(y_pred_probs)\n        predicted_label = y_pred_ensemble_svm[0]\n        st.subheader(f\"Prediction label: {predicted_label}\")\n        st.image(\"temp.png\", caption=\"Result Image\", use_container_width=True)\n    elif model_choice == \"Resnet18 + Ensemble Models\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, resnet18_model)\n        features_combined = image_features_resnet.reshape(1, -1)\n        y_pred1_prob = model1_resnet.predict(features_combined).flatten()\n        y_pred2_prob = model2_resnet.predict(features_combined).flatten()\n        y_pred3_prob = model3_resnet.predict(features_combined).flatten()\n        y_pred_probs = np.column_stack((y_pred1_prob, y_pred2_prob, y_pred3_prob))\n        y_pred_ensemble_svm = ensemble_model_svm_resnet.predict(y_pred_probs)\n        predicted_label = y_pred_ensemble_svm[0]\n        st.subheader(f\"Prediction label: {predicted_label}\")\n        st.image(\"temp.png\", caption=\"Result Image\", use_container_width=True)\n    elif model_choice == \"MobilenetV3 + PCA + SVM\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, mobilenet_v3_large_model)\n        image_features_pca = preprocess_image_pca(resized)\n        image_features_pca = pca_model_mobilenet_pca.transform(image_features_pca.reshape(1, -1))\n        features_combined = np.hstack((image_features_resnet.reshape(1, -1), image_features_pca))\n        features_combined = scaler_model_mobilenet_pca.transform(features_combined.reshape(1, -1))\n        y_pred = svm_model_mobilenet_pca.predict(features_combined)\n        predicted_label = y_pred[0]\n        img = load_img(\"temp.png\")\n        img_array = img_to_array(img)\n        st.subheader(f\"Prediction label: {y_pred[0]}\")\n        st.image(img_array.astype('uint8'), caption=f\"Predicted Label: {y_pred[0]}\", use_container_width=True)\n    elif model_choice == \"Resnet18 + PCA + SVM\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, resnet18_model)\n        image_features_pca = preprocess_image_pca(resized)\n        image_features_pca = pca_model_resnet_pca.transform(image_features_pca.reshape(1, -1))\n        features_combined = np.hstack((image_features_resnet.reshape(1, -1), image_features_pca))\n        features_combined = scaler_model_resnet_pca.transform(features_combined.reshape(1, -1))\n        y_pred = svm_model_resnet_pca.predict(features_combined)\n        predicted_label = y_pred[0]\n        img = load_img(\"temp.png\")\n        img_array = img_to_array(img)\n        st.subheader(f\"Prediction label: {y_pred[0]}\")\n        st.image(img_array.astype('uint8'), caption=f\"Predicted Label: {y_pred[0]}\", use_container_width=True)\n    elif model_choice == \"MobilenetV3 + PCA + Ensemble Models\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, mobilenet_v3_large_model)\n        image_features_pca = preprocess_image_pca(resized)\n        image_features_pca = pca_model_mobilenet_pca.transform(image_features_pca.reshape(1, -1))\n        features_combined = np.hstack((image_features_resnet.reshape(1, -1), image_features_pca))\n        y_pred1_prob = model1_mobilenet_pca.predict(features_combined).flatten()\n        y_pred2_prob = model2_mobilenet_pca.predict(features_combined).flatten()\n        y_pred3_prob = model3_mobilenet_pca.predict(features_combined).flatten()\n        y_pred_probs = np.column_stack((y_pred1_prob, y_pred2_prob, y_pred3_prob))\n        y_pred_ensemble_svm = ensemble_model_svm_mobilenet_pca.predict(y_pred_probs)\n        predicted_label = y_pred_ensemble_svm[0]\n        st.subheader(f\"Prediction label: {predicted_label}\")\n        st.image(\"temp.png\", caption=\"Result Image\", use_container_width=True)\n    elif model_choice == \"Resnet18 + PCA + Ensemble Models\":\n        img = preprocess_image(resized, device)\n        image_features_resnet = extract_features(img, resnet18_model)\n        image_features_pca = preprocess_image_pca(resized)\n        image_features_pca = pca_model_resnet_pca.transform(image_features_pca.reshape(1, -1))\n        features_combined = np.hstack((image_features_resnet.reshape(1, -1), image_features_pca))\n        y_pred1_prob = model1_resnet_pca.predict(features_combined).flatten()\n        y_pred2_prob = model2_resnet_pca.predict(features_combined).flatten()\n        y_pred3_prob = model3_resnet_pca.predict(features_combined).flatten()\n        y_pred_probs = np.column_stack((y_pred1_prob, y_pred2_prob, y_pred3_prob))\n        y_pred_ensemble_svm = ensemble_model_svm_resnet_pca.predict(y_pred_probs)\n        predicted_label = y_pred_ensemble_svm[0]\n        st.subheader(f\"Prediction label: {predicted_label}\")\n        st.image(\"temp.png\", caption=\"Result Image\", use_container_width=True)\n    if predicted_label == 1:\n            st.warning(\"Label is 1. Do you want to segment the image?\")\n            choice = st.radio(\"Select an option:\", (\"Yes\", \"No\"), index=1)\n        \n            if choice == \"Yes\":\n                st.write(\"You chose to segment the image.\")\n                # Add logic for image segmentation here\n                image_11 = color.rgb2gray(resized)\n                st.image(image_11, caption=\"1\", use_container_width=True)\n    \n                # Lấy kích thước và chuẩn bị dữ liệu\n                row, col = image_11.shape\n                image_11_2d = np.reshape(image_11, (row * col, 1))\n                \n                # Áp dụng Mean Shift\n                bandwidth = estimate_bandwidth(image_11_2d, quantile=0.2, n_samples=500)\n                mean_shift = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n                mean_shift_labels = mean_shift.fit_predict(image_11_2d)\n                \n                # Tạo ảnh phân đoạn\n                segmented_image_11 = mean_shift_labels.reshape((row, col))\n                \n                fig, ax = plt.subplots(figsize=(15, 5))\n                ax.imshow(segmented_image_11, cmap='viridis')\n                ax.axis('off')\n                \n                st.pyplot(fig)\n                st.caption(\"Segmented Image with Mean Shift Clustering\")\n                row, col = image_11.shape\n                image_11_2d = np.reshape(image_11, (row * col, 1))\n                # Áp dụng Mean Shift\n                bandwidth = estimate_bandwidth(image_11_2d, quantile=0.2, n_samples=50)\n                mean_shift = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n                mean_shift_labels = mean_shift.fit_predict(image_11_2d)\n                segmented_image_11 = mean_shift_labels.reshape((row, col))\n                \n                # Xử lý kích thước cụm\n                unique, counts = np.unique(segmented_image_11, return_counts=True)\n                cluster_sizes = dict(zip(unique, counts))\n                top_clusters = sorted(cluster_sizes, key=cluster_sizes.get, reverse=True)[:2]\n                \n                top_left_cluster = segmented_image_11[0, 0]\n                if top_left_cluster not in top_clusters:\n                    top_clusters.append(top_left_cluster)\n                    top_clusters = sorted(top_clusters, key=cluster_sizes.get, reverse=True)[:2]\n                \n                # Gán màu cho cụm\n                segmented_colored = np.zeros((row, col, 3), dtype=np.uint8)\n                for r in range(row):\n                    for c in range(col):\n                        if segmented_image_11[r, c] in top_clusters:\n                            original_color = plt.cm.viridis(segmented_image_11[r, c] / len(unique))[:3]\n                            segmented_colored[r, c] = (np.array(original_color) * 255).astype(np.uint8)\n                        else:\n                            segmented_colored[r, c] = [255, 0, 0]\n                 # Hiển thị ảnh với Streamlit\n                fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n                ax.imshow(segmented_colored)\n                ax.axis('off')\n                # Streamlit UI\n                st.title(\"Segmented Image with Highlighted Clusters\")\n                st.pyplot(fig)\n    \n    \n                red_channel = segmented_colored[:, :, 0]\n    \n                red_mask = red_channel == 255\n                \n                labeled, num_features = ndimage.label(red_mask)\n                \n                component_sizes = ndimage.sum(red_mask, labeled, range(num_features + 1))\n                \n                largest_component_label = np.argmax(component_sizes)\n                \n                largest_component_mask = labeled == largest_component_label\n                \n                final_segmented_colored = np.copy(segmented_colored)\n                final_segmented_colored[~largest_component_mask] = [0, 0, 0]\n    \n                # Hiển thị với Streamlit\n                fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n                ax.imshow(final_segmented_colored)\n                ax.axis('off')\n                # Streamlit UI\n                st.title(\"Largest Component in Red Regions\")\n                st.pyplot(fig)\n                st.caption(\"Only the largest connected component in red regions is preserved.\")\n                image_11_final = image_11.copy()\n\n                red_channel = final_segmented_colored[:, :, 0]\n                red_mask = red_channel == 255\n                \n                image_11_final = np.uint8(image_11 * 255)\n                \n                image_11_final_rgb = cv2.cvtColor(image_11_final, cv2.COLOR_GRAY2RGB)\n                \n                row, col = image_11_final.shape\n                \n                for r in range(row):\n                    for c in range(col):\n                        if red_mask[r, c]:\n                            image_11_final_rgb[r, c] = [255, 0, 0]\n                # Hiển thị với Streamlit\n                fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n                ax.imshow(image_11_final_rgb)\n                ax.axis('off')\n    \n                # Streamlit UI\n                st.title(\"Final Image\")\n                st.pyplot(fig)\n                \n    else:\n                st.write(\"You chose not to segment the image.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:12:46.027877Z","iopub.execute_input":"2024-12-10T16:12:46.028262Z","iopub.status.idle":"2024-12-10T16:12:46.044018Z","shell.execute_reply.started":"2024-12-10T16:12:46.028222Z","shell.execute_reply":"2024-12-10T16:12:46.043025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget -q -O - ipv4.icanhazip.com","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:12:46.044934Z","iopub.execute_input":"2024-12-10T16:12:46.045248Z","iopub.status.idle":"2024-12-10T16:12:47.093415Z","shell.execute_reply.started":"2024-12-10T16:12:46.045201Z","shell.execute_reply":"2024-12-10T16:12:47.092492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!streamlit run app_temp.py & npx localtunnel --port 8501","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:12:47.095826Z","iopub.execute_input":"2024-12-10T16:12:47.096233Z"}},"outputs":[],"execution_count":null}]}